{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaSilva-JV/AIED2025/blob/main/MaxMin_Allocating_Dynamic_and_Finite_Resources_to_a_set_of_known_Tasks_uu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZcNildGDzpQ",
        "outputId": "586f3687-0e2d-4916-f113-77e0ed8ac9c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pulp\n",
            "  Downloading PuLP-2.7.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pulp\n",
            "Successfully installed pulp-2.7.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to Collaboratory\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Install pulp\n",
        "!pip install pulp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p89y_cI4D7JY"
      },
      "outputs": [],
      "source": [
        "test_type = '1'\n",
        "test_name = {'1': 'mt', '2': 'cn', '3': 'ch', '4': 'lc'}\n",
        "directory_name = {'1': 'Matemática', '2': 'Ciências da Natureza', '3': 'Ciências Humanas', '4': 'Linguagens e Códigos'}\n",
        "\n",
        "\n",
        "# Getting the items' k-parameter\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/' + directory_name[test_type] + '/calculated_k_' + test_name[test_type] + '.csv')\n",
        "k = np.array(df['k_parameter'])\n",
        "\n",
        "# Getting the number of items solved for each volunteer (for all the 10.000)\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/' + directory_name[test_type] + '/n_correct_answers_' + test_name[test_type] + '.csv')\n",
        "n_solved = np.array(df['n_solved'])\n",
        "\n",
        "# Getting the sampled volunteers\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/Sampled_Volunteers.csv')\n",
        "sampled_volunteers = np.array(df['Volunteer'])\n",
        "\n",
        "# Getting the volunteers parameters (In the case of UU, we do not have any information about thetas)\n",
        "#df = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/' + directory_name[test_type] + '/Estimated_Theta_' + test_name[test_type] + '.csv')\n",
        "#all_theta = np.array(df['Theta'])\n",
        "\n",
        "# Load the 180 answers from the 10000 students\n",
        "df_respostas = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/file.txt', sep=' ', header=None)\n",
        "df_respostas = df_respostas.iloc[:, 0:175]\n",
        "\n",
        "if test_type == '1':\n",
        "    df_resp = df_respostas.iloc[:, 0:45]\n",
        "elif test_type == '2':\n",
        "    df_resp = df_respostas.iloc[:, 45:90]\n",
        "elif test_type == '3':\n",
        "    df_resp = df_respostas.iloc[:, 90:135]\n",
        "else:\n",
        "    df_resp = df_respostas.iloc[:, 135:175]\n",
        "\n",
        "# Load the parameters a, b and c for the 45 or 40 items\n",
        "df_param = pd.read_fwf('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/' + directory_name[test_type] + '/param_enem_' + test_name[test_type] + '.txt')\n",
        "\n",
        "# Add the type of the item\n",
        "df_param['Type'] = test_type\n",
        "\n",
        "# Put all parameters together\n",
        "df_items = df_param\n",
        "\n",
        "# Delete the column Unnamed\n",
        "del df_items['Unnamed: 0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZTMLuzgEi49",
        "outputId": "78ea9f91-e67a-42ab-aeb1-377748b95cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando episódio  66\n",
            "Iniciando episódio  67\n",
            "Iniciando episódio  68\n",
            "Iniciando episódio  69\n",
            "Iniciando episódio  70\n",
            "Iniciando episódio  71\n",
            "Iniciando episódio  72\n",
            "Iniciando episódio  73\n",
            "Iniciando episódio  74\n",
            "Iniciando episódio  75\n",
            "Iniciando episódio  76\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import pulp\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.auth import default\n",
        "import gspread_dataframe as gd\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# IRT (Three-Parameter Logistic Model)\n",
        "def prob_3pl(theta_, a_, b_, c_):\n",
        "    d = 1\n",
        "    return c_ + (1 - c_) * (1.0 / (1.0 + np.exp(d * a_ * (b_ - theta_))))\n",
        "\n",
        "\n",
        "# Modified EAP to update the theta estimate with each submission\n",
        "def expected_a_posteriori_mod(item, a, b, c, ans_presented, probs_, num_, presented):\n",
        "    # A priori distribution of theta (normal with mean 0 and std 1)\n",
        "    mu = 0\n",
        "    var = 1\n",
        "    theta_b = np.linspace(-4, 4, num=num_)\n",
        "    blf0 = norm.pdf(theta_b, mu, var)\n",
        "    blf0 = blf0 / sum(blf0)\n",
        "\n",
        "    # Calculated the probabilities using the IRT-3PL\n",
        "    probs_[item] = prob_3pl(theta_b, a, b, c)\n",
        "\n",
        "    # Update the blf with the Likelihood from the answers\n",
        "    blf = blf0\n",
        "\n",
        "    # print(presented)\n",
        "    # print(ans_presented)\n",
        "\n",
        "    for i, ans in enumerate(presented):  # for tasks already presented only\n",
        "        if ans_presented[i]:\n",
        "            blf = blf * probs_[ans, ]\n",
        "        else:\n",
        "            blf = blf * (1 - probs_[ans, ])\n",
        "        # Normalize after updated for all volunteers\n",
        "        blf = blf / sum(blf)\n",
        "\n",
        "    # theta_eap.append(sum(blf * theta_b))\n",
        "    theta_eap = sum(blf * theta_b)  # Calculating the average\n",
        "    # calculate cumulative sum\n",
        "\n",
        "    # Calculation of the Posterior Standard Deviation\n",
        "    psd = math.sqrt(sum(blf * (theta_b - theta_eap) ** 2))\n",
        "\n",
        "    return theta_eap, psd\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# IRT (Three-Parameter Logistic Model)\n",
        "def prob_irt_3pl(task_volunteer, a, b, c, theta):\n",
        "    i = task_volunteer[0]  # Task\n",
        "    j = task_volunteer[1]  # Volunteer\n",
        "    d = 1\n",
        "    return c[i] + (1 - c[i]) * (1.0 / (1.0 + math.exp(d * a[i] * (b[i] - theta[j]))))\n",
        "\n",
        "\n",
        "\n",
        "def linear_programming_mod(n_items, n_volunteers, a, b, c, theta, n_tries, n_solutions, vezes_resolvidas, ep):\n",
        "    # Create the 'prob' variable to contain the problem data\n",
        "    prob = pulp.LpProblem(\"ItemsVolunteers\", pulp.LpMaximize)\n",
        "\n",
        "    # create list of all possible combinations of questions and volunteers\n",
        "    possible_item_volunteer = [(i, j) for i in range(n_items) for j in range(n_volunteers)]\n",
        "\n",
        "    # create a binary variable to state that a question was presented to a volunteer\n",
        "    x = pulp.LpVariable.dicts(\"item_volunteer\", possible_item_volunteer, lowBound=0, upBound=1, cat=pulp.LpContinuous)\n",
        "\n",
        "    # The objective function is added to 'prob' first\n",
        "    #prob += pulp.lpSum([prob_irt_3pl(t_v, a, b, c, theta) * x[t_v] for t_v in possible_item_volunteer])\n",
        "    z = pulp.LpVariable(\"MenorNumeroDeSolucoes\", 0)\n",
        "    prob += z\n",
        "\n",
        "    # ----------- #\n",
        "    # Constraints #\n",
        "    # ----------- #\n",
        "    # specify the number of tries for each volunteer\n",
        "    for j in range(n_volunteers):\n",
        "        prob += pulp.lpSum([x[(i, j)] for i in range(n_items)]) <= n_tries[j]\n",
        "\n",
        "    # specify the desired quantity of solutions for each question\n",
        "    for i in range(n_items):\n",
        "        if (n_solutions[i] - vezes_resolvidas[i]) > 0:\n",
        "            #prob += pulp.lpSum([prob_irt_3pl((i, j), a, b, c, theta) * x[(i, j)] for j in range(n_volunteers)]) <= (n_solutions[i] - vezes_resolvidas[i])\n",
        "            # Restrictions to be able to do the minimax (maximize the minimum number of solutions)\n",
        "            prob += z <= pulp.lpSum([prob_irt_3pl((i, j), a, b, c, theta) * x[(i, j)] for j in range(n_volunteers)])\n",
        "        else:\n",
        "            prob += pulp.lpSum([prob_irt_3pl((i, j), a, b, c, theta) * x[(i, j)] for j in range(n_volunteers)]) == 0\n",
        "\n",
        "    # The problem data is written to an .lp file\n",
        "    prob.writeLP(\"ItemsVolunteers.lp\")\n",
        "\n",
        "    # The problem is solved using PuLP's choice of Solver\n",
        "    prob.solve()\n",
        "    # prob.solve(pulp.PULP_CBC_CMD(gapRel=0.1))\n",
        "    # status = prob.solve(solver=pulp.GLPK(msg=False))\n",
        "\n",
        "    # Write the solutions in a pandas dataframe\n",
        "    df = pd.DataFrame(columns=['item', 'volunteer', 'action'])\n",
        "    # Each of the variables is printed with it's resolved optimum value\n",
        "    for v in prob.variables():\n",
        "        if v.name != 'MenorNumeroDeSolucoes':\n",
        "            s = v.name.replace('item_volunteer_(', '').replace('_', '').replace(')', '')  # Leaves only the value of the item and the volunteer separated by a comma in a string\n",
        "            s_list = s.split(',')  # Transforms the string into a list\n",
        "\n",
        "            # Transforms string format to int in each list component\n",
        "            s_list[0] = int(s_list[0])\n",
        "            s_list[1] = int(s_list[1])\n",
        "\n",
        "            # Add the PL solution (corresponding to whether or not the item should be presented to the volunteer)\n",
        "            s_list.append(v.varValue)\n",
        "\n",
        "            # Add the solution to a dataframe\n",
        "            if s_list[2] > 0:\n",
        "                df = df.append(dict(zip(df.columns, s_list)), ignore_index=True)\n",
        "\n",
        "    #print('#------------------------------#')\n",
        "    #print(\"Total number of solutions = \", pulp.value(prob.objective))  # The optimised objective function value is printed to the screen\n",
        "    #print(\"Status:\", pulp.LpStatus[prob.status])  # The status of the solution is printed to the screen\n",
        "    #print(\"Episódio {}\".format(ep))  # The ongoing/finished episode\n",
        "    #print('#------------------------------#')\n",
        "\n",
        "    return df\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# Policy for choosing the tasks to volunteers\n",
        "def pl_policy(vol_, df_sol):\n",
        "    # Take the questions found from the IntegerProgramming\n",
        "    questions = df_sol[df_sol['volunteer'] == vol_]\n",
        "    w = list(questions['action'])\n",
        "\n",
        "    valid_questions = {'item': [], 'action_w': []}\n",
        "    # Checks if the task has not yet been presented to the volunteer and if it has not yet been solved the desired number of times\n",
        "    for j, q in enumerate(questions['item']):\n",
        "        q = int(q)\n",
        "        if (q not in tarefas_apresentadas[vol_]) and (vezes_resolvidas[q] < n_solutions[q]):\n",
        "            valid_questions['item'].append(q)\n",
        "            valid_questions['action_w'].append(w[j])\n",
        "\n",
        "    # Checks if there are tasks available for the user\n",
        "    if valid_questions['item']:\n",
        "        # if it exists, selects a task at random and adds the task to the list presented to the user\n",
        "        probs = np.array(valid_questions['action_w']) / sum(valid_questions['action_w'])\n",
        "        tarefa = np.random.choice(valid_questions['item'], p=probs)\n",
        "        return tarefa\n",
        "    else:\n",
        "        # The first available task is returned even if it was not selected by LP\n",
        "        for q in range(n_questions):\n",
        "            if (q not in tarefas_apresentadas[vol_]) and (vezes_resolvidas[q] < n_solutions[q]):\n",
        "                return q\n",
        "        return -1\n",
        "\n",
        "\n",
        "# Policy for choosing randomly tasks to volunteers\n",
        "def random_task(volunteer):\n",
        "    valid_questions = list()\n",
        "    for q in range(n_questions):\n",
        "        # Checks if the task has not yet been presented to the volunteer and if it has not yet been solved the desired number of times\n",
        "        if (q not in tarefas_apresentadas[volunteer]) and (vezes_resolvidas[q] < n_solutions[q]):\n",
        "            valid_questions.append(q)\n",
        "\n",
        "    # Checks if there are tasks available for the user\n",
        "    if valid_questions:\n",
        "        # if it exists, selects a task at random and adds the task to the list presented to the user\n",
        "        tarefa = np.random.choice(valid_questions)\n",
        "        return tarefa\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    process = 4  # Define the Process (0: easier first; 1: random; 2: per episode; 3: per resource; 4: per submission)\n",
        "    level = 2  # Levels to define n(t) and m(v)\n",
        "    n_episodes = 100   # Number of episodes\n",
        "\n",
        "    sheet_name = '24_jan_qtd_minimax_solucoes_uu_' + test_name[test_type] + '_' + str(process) + '_' + str(level)\n",
        "    sheet_name_ass = '24_jan_minimax_assignments_uu_' + test_name[test_type] + '_' + str(process) + '_' + str(level)\n",
        "\n",
        "    # Tries and solutions\n",
        "    dict_tries = {'1': 16, '2': 14, '3': 19, '4': 17}\n",
        "    if level == 0 or level == 1 or level == 2:\n",
        "        n_tries = np.array(10000 * [dict_tries[test_type]])  # Levels 0, 1 and 2\n",
        "    else:  # level == 3 or level == 4:\n",
        "        n_tries = n_solved  # Levels 3 and 4\n",
        "\n",
        "    # Tries and solutions\n",
        "    n_volunteers = 100\n",
        "    n_questions = df_param[df_param['Type'] == test_type].shape[0]\n",
        "\n",
        "    # Getting the items parameters\n",
        "    a = np.array(df_param[df_param['Type'] == test_type]['Dscrmn'])\n",
        "    b = np.array(df_param[df_param['Type'] == test_type]['Dffclt'])\n",
        "    c = np.array(df_param[df_param['Type'] == test_type]['Gussng'])\n",
        "\n",
        "    # Simulate for many episodes\n",
        "    qtd_total_solucoes = []\n",
        "    #qtd_total_presented = 0\n",
        "\n",
        "    for ep in range(38, n_episodes):\n",
        "        print('Iniciando episódio ',ep)\n",
        "\n",
        "        df_new_ep = pd.DataFrame()\n",
        "\n",
        "        # Initializes the time count\n",
        "        start = time.time()\n",
        "\n",
        "        # Authenticate to google spreadsheet\n",
        "        auth.authenticate_user()\n",
        "        #gc = gspread.authorize(GoogleCredentials.get_application_default())  # This token only lasts for one hour (you will only write one episode at a time)\n",
        "        creds, _ = default()\n",
        "        gc = gspread.authorize(creds)\n",
        "\n",
        "        #gc.login()  # Refreshes the token\n",
        "        # Creation of the spreadsheet\n",
        "        if ep == 0:\n",
        "            sh = gc.create(sheet_name)\n",
        "            sh_ass = gc.create(sheet_name_ass)\n",
        "\n",
        "        # Open our new sheet and add some data.\n",
        "        worksheet = gc.open(sheet_name).sheet1\n",
        "        gs_ass = gc.open(sheet_name_ass)\n",
        "        worksheet_ass = gs_ass.sheet1\n",
        "\n",
        "        # Load the parameters to solve the LP\n",
        "        n_tries_100 = n_tries[sampled_volunteers[(n_volunteers * ep):(n_volunteers * (ep + 1))]]\n",
        "        theta_100 = np.random.normal(0, 1, n_volunteers)        # unknown thetas (KU or UU)\n",
        "        # theta_100 = all_theta[sampled_volunteers[(n_volunteers * ep):(n_volunteers * (ep + 1))]]    # All known thetas (KK)\n",
        "\n",
        "        # Calculation of parameter k for each group of 100 sampled volunteers\n",
        "        perc_resp_correta = list()\n",
        "\n",
        "        for i in range(n_questions):\n",
        "            perc_resp_correta.append(df_resp.iloc[sampled_volunteers[(n_volunteers * ep):(n_volunteers * (ep + 1))], i].mean())\n",
        "\n",
        "        dict_sol = {'1': [12, 35], '2': [9, 29], '3': [17, 41], '4': [17, 41]}\n",
        "        if level == 0:\n",
        "            n_solutions = n_questions * [dict_sol[test_type][0]]  # Level 0\n",
        "        elif level == 1:\n",
        "            n_solutions = n_questions * [dict_sol[test_type][1]]  # Level 1\n",
        "        elif level == 2 or level == 3:\n",
        "            n_solutions = np.array(perc_resp_correta) * n_volunteers  # Levels 2 and 3\n",
        "        else:  # level == 4:\n",
        "            n_solutions = np.array(perc_resp_correta) * n_volunteers * 0.5  # Level 4\n",
        "\n",
        "        # Number of times each question was solved\n",
        "        vezes_resolvidas = np.zeros(n_questions)\n",
        "        qtd_total_presented = 0\n",
        "\n",
        "        # Tasks presented for each volunteer\n",
        "        tarefas_apresentadas = dict()\n",
        "        tentativas = dict()\n",
        "        respostas_apresentadas = dict()\n",
        "\n",
        "        # Matrix with the probabilities and the answers for each item\n",
        "        num = 1000\n",
        "        probs = np.zeros((n_questions, num))\n",
        "\n",
        "        if process == 2:\n",
        "            # Solving the LP\n",
        "            df_s = linear_programming_mod(n_questions, n_volunteers, a, b, c, theta_100, n_tries_100, n_solutions, vezes_resolvidas, ep)\n",
        "\n",
        "        # Each volunteer is assigned a task and the probability of the user solving it is calculated\n",
        "        for v_ in range(n_volunteers):\n",
        "            df_new_resource = pd.DataFrame()\n",
        "\n",
        "            if process == 3 or process == 4:\n",
        "                v = (n_volunteers - 1) - v_\n",
        "            else:\n",
        "                v = v_\n",
        "\n",
        "            # Each volunteer receives up to m different tasks\n",
        "            tentativas[v] = 0\n",
        "            tarefas_apresentadas[v] = list()\n",
        "            respostas_apresentadas[v] = list()\n",
        "\n",
        "            # Get the vector with the enem answers for volunteer v in episode ep\n",
        "            resp = np.array(df_resp.iloc[sampled_volunteers[v + n_volunteers * ep]])\n",
        "\n",
        "            '''\n",
        "            if process == 3:\n",
        "                # Estimate the theta of the current volunteer v\n",
        "                resp = np.array(df_resp.iloc[sampled_volunteers[v + n_volunteers * ep]])\n",
        "                theta_eap, _ = te.expected_a_posteriori(n_questions, a, b, c, resp)\n",
        "                theta_100[v] = theta_eap\n",
        "                # Solve the LP for each volunteer\n",
        "                df_s = lp.linear_programming_mod(n_questions, v + 1, a, b, c, theta_100, n_tries_100, n_solutions, vezes_resolvidas, ep)\n",
        "            '''\n",
        "            while tentativas[v] < n_tries[sampled_volunteers[v + n_volunteers * ep]]:\n",
        "                # Obtained the task to be presented to the volunteer\n",
        "                if process == 2 or process == 3:\n",
        "                    t = pl_policy(v, df_s)\n",
        "                elif process == 4:\n",
        "                    # Estimate the theta for volunteer v with each submission\\response\n",
        "\n",
        "                    if tentativas[v] == 0:\n",
        "                        t = random_task(v)\n",
        "\n",
        "                    theta_eap, _ = expected_a_posteriori_mod(t, a[t], b[t], c[t], respostas_apresentadas[v], probs, num, tarefas_apresentadas[v])\n",
        "                    theta_100[v] = theta_eap\n",
        "                    # Solve the LP for each submission (item presented to a volunteer)\n",
        "                    df_s = linear_programming_mod(n_questions, v + 1, a, b, c, theta_100, n_tries_100, n_solutions, vezes_resolvidas, ep)\n",
        "                    t = pl_policy(v, df_s)  # Presents a task and depending on the answer, the theta estimate will be updated and the next question to be presented will be updated\n",
        "\n",
        "                else:\n",
        "                    t = -1\n",
        "\n",
        "                if t == -1:\n",
        "                    break\n",
        "                else:\n",
        "                    # Verification by enem data if the student solved the task\n",
        "                    # resp = np.array(df_resp.iloc[sampled_volunteers[v + n_volunteers * ep]])\n",
        "                    resolvida = resp[t]\n",
        "\n",
        "                    # Updates the number of times that task has been solved and increases attempts\n",
        "                    vezes_resolvidas[t] += resolvida\n",
        "                    tentativas[v] += 1\n",
        "                    tarefas_apresentadas[v].append(t)\n",
        "                    respostas_apresentadas[v].append(resp[t])\n",
        "\n",
        "            qtd_total_presented += tentativas[v]\n",
        "\n",
        "            df_new_resource['Episódio'] = [ep]*len(tarefas_apresentadas[v])\n",
        "            df_new_resource['Recurso']  = [v]*len(tarefas_apresentadas[v])\n",
        "            df_new_resource['Tarefas apresentadas'] = tarefas_apresentadas[v]\n",
        "            df_new_resource['Respostas apresentadas'] = respostas_apresentadas[v]\n",
        "\n",
        "            df_new_ep = df_new_ep.append(df_new_resource)\n",
        "\n",
        "\n",
        "        qtd_total_solucoes.append(vezes_resolvidas.sum())\n",
        "\n",
        "        # Calculate the time at the and of the episode\n",
        "        end = time.time()\n",
        "\n",
        "        # Save the number of solutions at the end of each episode\n",
        "        cells = worksheet.range('A' + str(ep+1) + ':D' + str(ep+1))\n",
        "        cells[0].value = ep\n",
        "        cells[1].value = vezes_resolvidas.sum()\n",
        "        cells[2].value = end - start\n",
        "        cells[3].value = qtd_total_presented\n",
        "        worksheet.update_cells(cells)\n",
        "\n",
        "        if ep == 0:\n",
        "            gd.set_with_dataframe(worksheet=worksheet_ass, dataframe=df_new_ep, include_index=False, include_column_header=False)\n",
        "        else:\n",
        "            df_values = df_new_ep.values.tolist()\n",
        "            gs_ass.values_append('Página1', {'valueInputOption': 'RAW'}, {'values': df_values})\n",
        "\n",
        "\n",
        "    qtd_total_solucoes = np.array(qtd_total_solucoes)\n",
        "\n",
        "\n",
        "    # Printing the results\n",
        "    print('\\nProcess: {0}, Level: {1}'.format(process, level))\n",
        "    print(\"Mean of solutions for simulating {0} times: {1}\".format(n_episodes, np.mean(qtd_total_solucoes)))\n",
        "    print(\"Standard deviation of solutions for simulating {0} times: {1}\".format(n_episodes, np.std(qtd_total_solucoes)))\n",
        "    #print(\"Mean of tries for simulating {0} times: {1}\".format(n_episodes, qtd_total_presented / n_episodes))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBNqyvIdn7Tai0pvJWEKhg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}