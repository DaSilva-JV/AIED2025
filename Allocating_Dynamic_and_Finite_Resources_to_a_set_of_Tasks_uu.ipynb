{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaSilva-JV/AIED2025/blob/main/Allocating_Dynamic_and_Finite_Resources_to_a_set_of_Tasks_uu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvE0Ifz54tbe",
        "outputId": "6ed71c72-57af-49df-e09d-2f6ba903db27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pulp\n",
            "  Downloading PuLP-2.7.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pulp\n",
            "Successfully installed pulp-2.7.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to Collaboratory\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Install pulp\n",
        "!pip install pulp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw_ON4fC46pe"
      },
      "outputs": [],
      "source": [
        "test_type = '1'\n",
        "test_name = {'1': 'mt', '2': 'cn', '3': 'ch', '4': 'lc'}\n",
        "directory_name = {'1': 'Matemática', '2': 'Ciências da Natureza', '3': 'Ciências Humanas', '4': 'Linguagens e Códigos'}\n",
        "\n",
        "\n",
        "# Getting the tasks k-parameter\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/' + directory_name[test_type] + '/calculated_k_' + test_name[test_type] + '.csv')\n",
        "k = np.array(df['k_parameter'])\n",
        "\n",
        "# Getting the number of items solved for each volunteer (for all the 10.000)\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/' + directory_name[test_type] + '/n_correct_answers_' + test_name[test_type] + '.csv')\n",
        "n_solved = np.array(df['n_solved'])\n",
        "\n",
        "# Getting the sampled volunteers\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/Sampled_Volunteers.csv')\n",
        "sampled_volunteers = np.array(df['Volunteer'])\n",
        "\n",
        "# Getting the volunteers parameters (in the case of UU, we do not have any information about thetas)\n",
        "#df = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/' + directory_name[test_type] + '/Estimated_Theta_' + test_name[test_type] + '.csv')\n",
        "#all_theta = np.array(df['Theta'])\n",
        "\n",
        "# Load the 180 answers from the 10000 students\n",
        "df_respostas = pd.read_csv('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/file.txt', sep=' ', header=None)\n",
        "df_respostas = df_respostas.iloc[:, 0:175]\n",
        "\n",
        "if test_type == '1':\n",
        "    df_resp = df_respostas.iloc[:, 0:45]\n",
        "elif test_type == '2':\n",
        "    df_resp = df_respostas.iloc[:, 45:90]\n",
        "elif test_type == '3':\n",
        "    df_resp = df_respostas.iloc[:, 90:135]\n",
        "else:\n",
        "    df_resp = df_respostas.iloc[:, 135:175]\n",
        "\n",
        "\n",
        "#print(df_resp)\n",
        "\n",
        "\n",
        "'''\n",
        "# Load the parameters a, b and c for the 45 or 40 items\n",
        "df_param = pd.read_fwf('/content/gdrive/MyDrive/Allocating Dynamic and Finite Resources to a set of known Tasks/' + directory_name[test_type] + '/param_enem_' + test_name[test_type] + '.txt')\n",
        "\n",
        "# Add the type of the item\n",
        "df_param['Type'] = test_type\n",
        "\n",
        "# Put all parameters together\n",
        "df_items = df_param\n",
        "\n",
        "# Delete the column Unnamed\n",
        "del df_items['Unnamed: 0']\n",
        "'''\n",
        "\n",
        "\n",
        "# Prior Mean and STD Deviation on log(a) [a follows a lognormal distribution]\n",
        "pm_alpha = 0.0\n",
        "pv_alpha = 0.5\n",
        "pv_alpha = pv_alpha**2\n",
        "\n",
        "\n",
        "# Prior Mean and STD Deviation on b [b follows a normal distribution]\n",
        "pm_b = 0.0\n",
        "pv_b = 1\n",
        "pv_b = pv_b**2\n",
        "\n",
        "\n",
        "# Prior Mean and STD Deviation on c [c follows a beta distribution]\n",
        "# For these values, p = 0.2. For values ​​(5, 23); we have p = 0.15\n",
        "# This value would be the shot hit value\n",
        "alp_c = 5\n",
        "bet_c = 17\n",
        "\n",
        "\n",
        "# Values ​​for theta ranges\n",
        "x = [-4.0000, -3.1111, -2.2222, -1.3333, -0.4444, 0.4444, 1.3333, 2.2222, 3.1111, 4.0000]\n",
        "ak = [0.000119, 0.002805, 0.03002, 0.1458, 0.3213, 0.3213, 0.1458, 0.03002, 0.002805, 0.000119]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5pzusIx49Oq",
        "outputId": "8cd6dcba-c91e-47b4-8b24-50f30dea2dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando episódio  94\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import pulp\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.auth import default\n",
        "import gspread_dataframe as gd\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# IRT (Three-Parameter Logistic Model) model\n",
        "def prob_3pl(theta_, a_, b_, c_):\n",
        "    d = 1\n",
        "    return c_ + (1 - c_) * (1.0 / (1.0 + np.exp(d * a_ * (b_ - theta_))))\n",
        "\n",
        "\n",
        "# Modified EAP to update the theta estimate with each submission\n",
        "def expected_a_posteriori_mod(item, a, b, c, ans_presented, probs_, num_, presented):\n",
        "    # A priori distribution of theta (normal with mean 0 and std 1)\n",
        "    mu = 0\n",
        "    var = 1\n",
        "    theta_b = np.linspace(-4, 4, num=num_)\n",
        "    blf0 = norm.pdf(theta_b, mu, var)\n",
        "    blf0 = blf0 / sum(blf0)\n",
        "\n",
        "    # Calculated the probabilities using the IRT-3PL\n",
        "    probs_[item] = prob_3pl(theta_b, a, b, c)\n",
        "\n",
        "    # Update the blf with the Likelihood from the answers\n",
        "    blf = blf0\n",
        "\n",
        "    # print(presented)\n",
        "    # print(ans_presented)\n",
        "\n",
        "    for i, ans in enumerate(presented):  # for tasks already presented only\n",
        "        if ans_presented[i]:\n",
        "            blf = blf * probs_[ans, ]\n",
        "        else:\n",
        "            blf = blf * (1 - probs_[ans, ])\n",
        "        # Normalize after updated for all volunteers\n",
        "        blf = blf / sum(blf)\n",
        "\n",
        "    # theta_eap.append(sum(blf * theta_b))\n",
        "    theta_eap = sum(blf * theta_b)  # Calculating the average\n",
        "\n",
        "    # calculate cumulative sum\n",
        "\n",
        "    # Calculation of the Posterior Standard Deviation\n",
        "    psd = math.sqrt(sum(blf * (theta_b - theta_eap) ** 2))\n",
        "\n",
        "    return theta_eap, psd\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# IRT (Three-Parameter Logistic Model)\n",
        "def prob_irt_3pl(task_volunteer, a, b, c, theta):\n",
        "    i = task_volunteer[0]  # Task\n",
        "    j = task_volunteer[1]  # Volunteer\n",
        "    d = 1\n",
        "    return c[i] + (1 - c[i]) * (1.0 / (1.0 + math.exp(d * a[i] * (b[i] - theta[j]))))\n",
        "\n",
        "\n",
        "\n",
        "def linear_programming_mod(n_items, n_volunteers, a, b, c, theta, n_tries, n_solutions, vezes_resolvidas, ep):\n",
        "    # Create the 'prob' variable to contain the problem data\n",
        "    prob = pulp.LpProblem(\"ItemsVolunteers\", pulp.LpMaximize)\n",
        "\n",
        "    # create list of all possible combinations of questions and volunteers\n",
        "    possible_item_volunteer = [(i, j) for i in range(n_items) for j in range(n_volunteers)]\n",
        "\n",
        "    # create a binary variable to state that a question was presented to a volunteer\n",
        "    x = pulp.LpVariable.dicts(\"item_volunteer\", possible_item_volunteer, lowBound=0, upBound=1, cat=pulp.LpContinuous)\n",
        "\n",
        "    # The objective function is added to 'prob' first\n",
        "    prob += pulp.lpSum([prob_irt_3pl(t_v, a, b, c, theta) * x[t_v] for t_v in possible_item_volunteer])\n",
        "\n",
        "    # ----------- #\n",
        "    # Constraints #\n",
        "    # ----------- #\n",
        "    # specify the number of tries for each volunteer\n",
        "    for j in range(n_volunteers):\n",
        "        prob += pulp.lpSum([x[(i, j)] for i in range(n_items)]) <= n_tries[j]\n",
        "\n",
        "    # specify the desired quantity of solutions for each question\n",
        "    for i in range(n_items):\n",
        "        if (n_solutions[i] - vezes_resolvidas[i]) > 0:\n",
        "            prob += pulp.lpSum([prob_irt_3pl((i, j), a, b, c, theta) * x[(i, j)] for j in range(n_volunteers)]) <= (n_solutions[i] - vezes_resolvidas[i])\n",
        "        else:\n",
        "            prob += pulp.lpSum([prob_irt_3pl((i, j), a, b, c, theta) * x[(i, j)] for j in range(n_volunteers)]) == 0\n",
        "\n",
        "    # The problem data is written to an .lp file\n",
        "    prob.writeLP(\"ItemsVolunteers.lp\")\n",
        "\n",
        "    pulp.LpSolverDefault.msg = 1\n",
        "\n",
        "    # The problem is solved using PuLP's choice of Solver\n",
        "    prob.solve()\n",
        "    # prob.solve(pulp.PULP_CBC_CMD(gapRel=0.1))\n",
        "    # status = prob.solve(solver=pulp.GLPK(msg=False))\n",
        "\n",
        "    # Write the solutions in a pandas dataframe\n",
        "    df = pd.DataFrame(columns=['item', 'volunteer', 'action'])\n",
        "    # Each of the variables is printed with it's resolved optimum value\n",
        "    for v in prob.variables():\n",
        "        s = v.name.replace('item_volunteer_(', '').replace('_', '').replace(')', '')  # Leaves only the value of the item and the volunteer separated by a comma in a string\n",
        "        s_list = s.split(',')  # Transforms the string into a list\n",
        "\n",
        "        # Transforms string format to int in each list component\n",
        "        s_list[0] = int(s_list[0])\n",
        "        s_list[1] = int(s_list[1])\n",
        "\n",
        "        # Add the PL solution (corresponding to whether or not the item should be presented to the volunteer)\n",
        "        s_list.append(v.varValue)\n",
        "\n",
        "        # Add the solution to a dataframe\n",
        "        if s_list[2] > 0:\n",
        "            df = df.append(dict(zip(df.columns, s_list)), ignore_index=True)\n",
        "\n",
        "    #print('#------------------------------#')\n",
        "    #print(\"Total number of solutions = \", pulp.value(prob.objective))  # The optimised objective function value is printed to the screen\n",
        "    #print(\"Status:\", pulp.LpStatus[prob.status])  # The status of the solution is printed to the screen\n",
        "    #print(\"Episódio {}\".format(ep))  # The ongoing/finished episode\n",
        "    #print('#------------------------------#')\n",
        "\n",
        "    return df\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# Policy for choosing the tasks to volunteers\n",
        "def pl_policy(vol_, df_sol):\n",
        "    # Take the questions found from the IntegerProgramming\n",
        "    questions = df_sol[df_sol['volunteer'] == vol_]\n",
        "    w = list(questions['action'])\n",
        "\n",
        "    valid_questions = {'item': [], 'action_w': []}\n",
        "    # Checks if the task has not yet been presented to the volunteer and if it has not yet been solved the desired number of times\n",
        "    for j, q in enumerate(questions['item']):\n",
        "        q = int(q)\n",
        "        if (q not in tarefas_apresentadas[vol_]) and (vezes_resolvidas[q] < n_solutions[q]):\n",
        "            valid_questions['item'].append(q)\n",
        "            valid_questions['action_w'].append(w[j])\n",
        "\n",
        "    # Checks if there are tasks available for the user\n",
        "    if valid_questions['item']:\n",
        "        # if it exists, selects a task at random and adds the task to the list presented to the user\n",
        "        probs = np.array(valid_questions['action_w']) / sum(valid_questions['action_w'])\n",
        "        tarefa = np.random.choice(valid_questions['item'], p=probs)\n",
        "        return tarefa\n",
        "    else:\n",
        "        # The first available task is returned even if it was not selected by LP\n",
        "        for q in range(n_questions):\n",
        "            if (q not in tarefas_apresentadas[vol_]) and (vezes_resolvidas[q] < n_solutions[q]):\n",
        "                return q\n",
        "        return -1\n",
        "\n",
        "\n",
        "# Policy for choosing randomly tasks to volunteers\n",
        "def random_task(volunteer):\n",
        "    valid_questions = list()\n",
        "    for q in range(n_questions):\n",
        "        # Checks if the task has not yet been presented to the volunteer and if it has not yet been solved the desired number of times\n",
        "        if (q not in tarefas_apresentadas[volunteer]) and (vezes_resolvidas[q] < n_solutions[q]):\n",
        "            valid_questions.append(q)\n",
        "\n",
        "    # Checks if there are tasks available for the user\n",
        "    if valid_questions:\n",
        "        # if it exists, selects a task at random and adds the task to the list presented to the user\n",
        "        tarefa = np.random.choice(valid_questions)\n",
        "        return tarefa\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Program to implement marginalized bayesian item parameter estimation\n",
        "# B = difficulty\n",
        "# A = discrimination\n",
        "# C = guessing\n",
        "def bayesian_item_parameter_estimation(pl, lxk, rik, fik, u_li, item, vol, a_i, b_i, c_i):\n",
        "\n",
        "    # Item Scores Pattern Frequencies\n",
        "    # fpt(l) is the number of resources in each response pattern of the T tasks\n",
        "    fpt = np.ones(n_volunteers)\n",
        "\n",
        "    # Number of EM algorithm cycles (E-step and M-step cycles)\n",
        "    mnc = 1\n",
        "\n",
        "    for nc in range(mnc):\n",
        "        #print(\"Ciclo = {}\".format(nc))\n",
        "\n",
        "\n",
        "        # E-step: get expected R and N\n",
        "        #for l in range(n_volunteers):\n",
        "        for k in range(10):\n",
        "            #pq = []\n",
        "            #for i in range(n_questions):\n",
        "\n",
        "            # Calculations of P*(x), Q*(x), P(x) and Q(x)\n",
        "            dev = - a_i*(x[k] - b_i)\n",
        "            p_star = 1/(1 + math.exp(dev))\n",
        "            q_star = 1 - p_star\n",
        "\n",
        "            p = c_i + (1 - c_i)*p_star\n",
        "            q = 1 - p\n",
        "\n",
        "            '''\n",
        "            # Get the result of the answer for pattern l and item i\n",
        "            u_li = df_volunts[df_volunts[\"Padrão Resp\"] == vol][\"Item \" + str(item)]\n",
        "            if u_li.count() == 0:  # Checks if the result is empty\n",
        "                continue\n",
        "            else:\n",
        "                u_li = u_li.iloc[0]\n",
        "            '''\n",
        "\n",
        "            if u_li == 1:\n",
        "                pq = p  # The probability of success\n",
        "            else:\n",
        "                pq = q  # The probability of error (1-p)\n",
        "\n",
        "            try:\n",
        "                lxk[vol,k] = lxk[vol,k] * pq\n",
        "            except:\n",
        "                print(\"Vol = {}\".format(vol))\n",
        "                print(\"Item = {}\".format(item))\n",
        "                print(\"LXK shape = {}\".format(lxk.shape))\n",
        "                print(\"PQ length = {}\".format(len(pq)))\n",
        "                raise(\"Erro!!\")\n",
        "\n",
        "        pl[vol] = 0\n",
        "        for k in range(10):\n",
        "            pl[vol] = pl[vol] + lxk[vol,k] * ak[k]\n",
        "\n",
        "\n",
        "        #for i in range(n_questions):\n",
        "        for k in range(10):\n",
        "        #for l in range(2**n_questions):\n",
        "\n",
        "            '''\n",
        "            # Get the result of the answer for pattern l and item i\n",
        "            u_li = df_volunts[df_volunts[\"Padrão Resp\"] == vol][\"Item \" + str(item)]\n",
        "            if u_li.count() == 0:  # Checks if the result is empty\n",
        "                continue\n",
        "            else:\n",
        "                u_li = u_li.iloc[0]\n",
        "            '''\n",
        "\n",
        "            nt = (fpt[vol]*lxk[vol,k]*ak[k])/pl[vol]\n",
        "            rt = nt*u_li\n",
        "            rik[item,k] = rik[item,k] + rt\n",
        "            fik[item,k] = fik[item,k] + nt\n",
        "\n",
        "        # M-step: Bayes modal estimation of item parameters\n",
        "        alpha = np.zeros(n_questions)\n",
        "\n",
        "        #for i in range(n_questions):\n",
        "        for nit in range(n_questions + 1):\n",
        "\n",
        "            alpha_i = math.log(a_i)\n",
        "\n",
        "            L1 = 0\n",
        "            L2 = 0\n",
        "            L3 = 0\n",
        "\n",
        "            A11 = 0\n",
        "            A22 = 0\n",
        "            A33 = 0\n",
        "\n",
        "            A12 = 0\n",
        "            A13 = 0\n",
        "            A23 = 0\n",
        "\n",
        "            # Theta loop\n",
        "            for k in range(10):\n",
        "                if fik[item,k] == 0:\n",
        "                    continue\n",
        "\n",
        "                # Cálculo de P*(x), Q*(x), P(x) e Q(x)\n",
        "                dev = - a_i*(x[k] - b_i)\n",
        "                p_star = 1/(1 + math.exp(dev))\n",
        "                q_star = 1 - p_star\n",
        "\n",
        "                p = c_i + (1 - c_i)*p_star\n",
        "                q = 1 - p\n",
        "\n",
        "                # Wik calculation for three parameters\n",
        "                if p*q > 0.0000009:\n",
        "                    w =  (p_star*q_star) / (p*q)\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                if (w < 0.0000009) or (w > 1e10):\n",
        "                    continue\n",
        "\n",
        "                rmf = rik[item,k] - fik[item,k]*p\n",
        "                xmb = x[k] - b_i\n",
        "                xmb2 = xmb**2\n",
        "\n",
        "                pmc = p - c_i\n",
        "                umc = 1 - c_i\n",
        "                umc2 = umc**2\n",
        "                pmc2 = pmc**2\n",
        "\n",
        "                # -------------------------------------- #\n",
        "                # Quadrature sum increments #\n",
        "                # -------------------------------------- #\n",
        "                # Likelihood of the first derivative with respect to parameters a, b and c\n",
        "                L1 += rmf*xmb*w\n",
        "                L2 += rmf*w\n",
        "                L3 += rmf/p\n",
        "\n",
        "                # The expectation of the second and cross derivatives\n",
        "                A11 += fik[item,k] * xmb2 * (pmc2/umc2) * (q/p)\n",
        "                A22 += fik[item,k] * (pmc2/umc2) * (q/p)\n",
        "                A33 += (fik[item,k]/umc2) * (q/p)\n",
        "\n",
        "                A12 += fik[item,k] * xmb * (pmc2/umc2) * (q/p)\n",
        "                A13 += fik[item,k] * xmb * (pmc/umc2) * (q/p)\n",
        "                A23 += fik[item,k] * (pmc/umc2) * (q/p)\n",
        "\n",
        "            # Calculates the exponential of alpha\n",
        "            ea = math.exp(alpha_i)\n",
        "            ea2 = ea**2\n",
        "\n",
        "            # Multiply by EA and ADD prior terms\n",
        "            L1 = ea*umc*L1 - (alpha_i - pm_alpha)/pv_alpha\n",
        "            L2 = - ea*umc*L2 - (b_i - pm_b)/pv_b\n",
        "            L3 = L3/umc + (alp_c - 2)/c_i - (bet_c - 2)/umc\n",
        "\n",
        "            A11 = - ea2*A11 - 1/pv_alpha\n",
        "            A22 = - ea2*A22 - 1/pv_b\n",
        "            A33 = - A33 - ((alp_c - 2)/(c_i**2)) - ((bet_c - 2)/umc2)\n",
        "\n",
        "            A12 = ea2*A12\n",
        "            A13 = - ea2*A13\n",
        "            A23 = ea*A23\n",
        "\n",
        "            # Calculation of the determinant of the 3x3 matrix of A's:\n",
        "            #  A11 A12 A13\n",
        "            #  A21 A22 A23\n",
        "            #  A31 A32 A33\n",
        "            # with A12 = A21; A13 = A31; A23 = A32\n",
        "            det = A11*A22*A33 + 2*A12*A13*A23 - (A11*(A23**2) + A22*(A13**2) + A33*(A12**2))\n",
        "\n",
        "            if abs(det) <= 0.000099:\n",
        "                print(\"Out of bounds error\")\n",
        "                print('Determinante = {}'.format(det))\n",
        "                a_i = math.exp(alpha_i)\n",
        "                break\n",
        "\n",
        "            # psi(t+1) = psi(t) - [Aij]^(-1) * [L]\n",
        "            # To calculate the inverse of [Aij], we calculate its determinant and the cofactor matrix:\n",
        "            C11 = A22*A33 - A23**2\n",
        "            C22 = A11*A33 - A13**2\n",
        "            C33 = A11*A22 - A12**2\n",
        "\n",
        "            C12 = A13*A23 - A12*A33\n",
        "            C13 = A12*A23 - A13*A22\n",
        "            C23 = A12*A13 - A23*A11\n",
        "\n",
        "            # Increment calculation for each parameter a, b and c\n",
        "            da = (C11*L1 + C12*L2 + C13*L3)/det\n",
        "            db = (C12*L1 + C22*L2 + C23*L3)/det\n",
        "            dc = (C13*L1 + C23*L2 + C33*L3)/det\n",
        "\n",
        "            alpha_i = alpha_i - da\n",
        "            b_i = b_i - db\n",
        "            c_i = c_i - dc\n",
        "            a_i = math.exp(alpha_i)\n",
        "\n",
        "            if abs(alpha_i) > 30 or abs(b_i) > 20 or abs(c_i) > 20:\n",
        "                print(\"Out of bounds error\")\n",
        "                alpha_i = 0.0\n",
        "                b_i = 0.0\n",
        "                c_i = 0.2\n",
        "                a_i = math.exp(alpha_i)\n",
        "                break\n",
        "\n",
        "            if abs(da) <= 0.05 and abs(db) <= 0.05 and abs(dc) <= 0.05:\n",
        "                #print(\"Convergence criterion achieved\")\n",
        "                break\n",
        "\n",
        "    return [pl, lxk, rik, fik, a_i, b_i, c_i]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    process = 4  # Define the Process\n",
        "    level = 2  # Levels to define n(t) and m(v)\n",
        "    n_episodes = 100   # Number of episodes\n",
        "\n",
        "    sheet_name = 'test_unknown_tasks_qtd_solucoes_uu_' + test_name[test_type] + '_' + str(process) + '_' + str(level)\n",
        "    sheet_name_ass = 'test_unknown_tasks_assignments_uu_' + test_name[test_type] + '_' + str(process) + '_' + str(level)\n",
        "    sheet_name_tasks_param = 'test_unknown_tasks_parameters_uu_' + test_name[test_type] + '_' + str(process) + '_' + str(level)\n",
        "\n",
        "    # Tries and solutions\n",
        "    dict_tries = {'1': 16, '2': 14, '3': 19, '4': 17}\n",
        "    if level == 0 or level == 1 or level == 2:\n",
        "        n_tries = np.array(10000 * [dict_tries[test_type]])  # Levels 0, 1 and 2\n",
        "    else:  # level == 3 or level == 4:\n",
        "        n_tries = n_solved  # Levels 3 and 4\n",
        "\n",
        "    # Tries and solutions\n",
        "    n_volunteers = 100\n",
        "    n_questions = 45\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    # Getting the items parameters\n",
        "    a = np.array(df_param[df_param['Type'] == test_type]['Dscrmn'])\n",
        "    b = np.array(df_param[df_param['Type'] == test_type]['Dffclt'])\n",
        "    c = np.array(df_param[df_param['Type'] == test_type]['Gussng'])\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    # Simulate for many episodes\n",
        "    qtd_total_solucoes = []\n",
        "    #qtd_total_presented = 0\n",
        "\n",
        "    for ep in range(94, n_episodes):\n",
        "        print('Iniciando episódio ',ep)\n",
        "\n",
        "        pl = np.zeros(n_volunteers)\n",
        "        lxk = np.ones((n_volunteers, 10))\n",
        "\n",
        "\n",
        "        # Initialization of item parameters to be estimated\n",
        "        b = np.zeros(n_questions)\n",
        "        a = np.ones(n_questions)\n",
        "        c = []\n",
        "        for i in range(n_questions):\n",
        "            c.append(0.2)\n",
        "\n",
        "        # r bar and f bar loop\n",
        "        rik = np.zeros((n_questions, 10))\n",
        "        fik = np.zeros((n_questions, 10))  # it is the \"nk\"\n",
        "\n",
        "\n",
        "        # Dataframe with resource responses from the current episode\n",
        "        df_resp_episode = df_resp.iloc[sampled_volunteers[(n_volunteers * ep):(n_volunteers * (ep + 1))]]\n",
        "\n",
        "        s = list(df_resp_episode.sum(axis=1))  # FREQUENCY OF RAW SCORES FOR 1 TO MAXSCORE\n",
        "        fdg = list(df_resp_episode.sum(axis=0))  # ITEM SCORE FREQUENCY\n",
        "\n",
        "        # Defines the dataframe that will contain the information for the assignment excel\n",
        "        df_new_ep = pd.DataFrame()\n",
        "\n",
        "        # Defines the dataframe that will contain information for Excel about task parameters\n",
        "        df_new_ep_tasks_param = pd.DataFrame()\n",
        "\n",
        "        # Initializes the time count\n",
        "        start = time.time()\n",
        "\n",
        "        # Authenticate to google spreadsheet\n",
        "        auth.authenticate_user()\n",
        "        #gc = gspread.authorize(GoogleCredentials.get_application_default())  # This token only lasts for one hour (you will only write one episode at a time)\n",
        "        creds, _ = default()\n",
        "        gc = gspread.authorize(creds)\n",
        "\n",
        "        #gc.login()  # Refreshes the token\n",
        "        # Creation of the spreadsheet\n",
        "        if ep == 0:\n",
        "            sh = gc.create(sheet_name)\n",
        "            sh_ass = gc.create(sheet_name_ass)\n",
        "            sh_task_param = gc.create(sheet_name_tasks_param)\n",
        "\n",
        "        # Open our new sheet and add some data.\n",
        "        worksheet = gc.open(sheet_name).sheet1\n",
        "\n",
        "        gs_ass = gc.open(sheet_name_ass)\n",
        "        worksheet_ass = gs_ass.sheet1\n",
        "\n",
        "        gs_tasks_param = gc.open(sheet_name_tasks_param)\n",
        "        worksheet_tasks_param = gs_tasks_param.sheet1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Load the parameters to solve the LP\n",
        "        n_tries_100 = n_tries[sampled_volunteers[(n_volunteers * ep):(n_volunteers * (ep + 1))]]\n",
        "        theta_100 = np.random.normal(0, 1, n_volunteers)        # unknown thetas (KU or UU)\n",
        "        # theta_100 = all_theta[sampled_volunteers[(n_volunteers * ep):(n_volunteers * (ep + 1))]]    # All known thetas (KK)\n",
        "\n",
        "        # Calculation of parameter k for each group of 100 sampled volunteers\n",
        "        perc_resp_correta = list()\n",
        "\n",
        "        for i in range(n_questions):\n",
        "            perc_resp_correta.append(df_resp.iloc[sampled_volunteers[(n_volunteers * ep):(n_volunteers * (ep + 1))], i].mean())\n",
        "\n",
        "        dict_sol = {'1': [12, 35], '2': [9, 29], '3': [17, 41], '4': [17, 41]}\n",
        "        if level == 0:\n",
        "            n_solutions = n_questions * [dict_sol[test_type][0]]  # Level 0\n",
        "        elif level == 1:\n",
        "            n_solutions = n_questions * [dict_sol[test_type][1]]  # Level 1\n",
        "        elif level == 2 or level == 3:\n",
        "            n_solutions = np.array(perc_resp_correta) * n_volunteers  # Levels 2 and 3\n",
        "        else:  # level == 4:\n",
        "            n_solutions = np.array(perc_resp_correta) * n_volunteers * 0.5  # Level 4\n",
        "\n",
        "        # Number of times each question was solved\n",
        "        vezes_resolvidas = np.zeros(n_questions)\n",
        "        qtd_total_presented = 0\n",
        "\n",
        "        # Tasks presented for each volunteer\n",
        "        tarefas_apresentadas = dict()\n",
        "        tentativas = dict()\n",
        "        respostas_apresentadas = dict()\n",
        "\n",
        "        # Matrix with the probabilities and the answers for each item\n",
        "        num = 1000\n",
        "        probs = np.zeros((n_questions, num))\n",
        "\n",
        "        if process == 2:\n",
        "            # Solving the LP\n",
        "            df_s = linear_programming_mod(n_questions, n_volunteers, a, b, c, theta_100, n_tries_100, n_solutions, vezes_resolvidas, ep)\n",
        "\n",
        "        # Each volunteer is assigned a task and the probability of the user solving it is calculated\n",
        "        for v_ in range(n_volunteers):\n",
        "            df_new_resource = pd.DataFrame()\n",
        "\n",
        "            if process == 3 or process == 4:\n",
        "                v = (n_volunteers - 1) - v_\n",
        "            else:\n",
        "                v = v_\n",
        "\n",
        "            # Each volunteer receives up to m different tasks\n",
        "            tentativas[v] = 0\n",
        "            tarefas_apresentadas[v] = list()\n",
        "            respostas_apresentadas[v] = list()\n",
        "\n",
        "            # Get the vector with the enem answers for volunteer v in episode ep\n",
        "            resp = np.array(df_resp.iloc[sampled_volunteers[v + n_volunteers * ep]])\n",
        "\n",
        "            '''\n",
        "            if process == 3:\n",
        "                # Estimate the theta of the current volunteer v\n",
        "                resp = np.array(df_resp.iloc[sampled_volunteers[v + n_volunteers * ep]])\n",
        "                theta_eap, _ = te.expected_a_posteriori(n_questions, a, b, c, resp)\n",
        "                theta_100[v] = theta_eap\n",
        "                # Solve the LP for each volunteer\n",
        "                df_s = lp.linear_programming_mod(n_questions, v + 1, a, b, c, theta_100, n_tries_100, n_solutions, vezes_resolvidas, ep)\n",
        "            '''\n",
        "            while tentativas[v] < n_tries[sampled_volunteers[v + n_volunteers * ep]]:\n",
        "                # Obtained the task to be presented to the volunteer\n",
        "                if process == 2 or process == 3:\n",
        "                    t = pl_policy(v, df_s)\n",
        "                elif process == 4:\n",
        "                    # Estimate the theta for volunteer v with each submission\\response\n",
        "\n",
        "                    if tentativas[v] == 0:\n",
        "                        t = random_task(v)\n",
        "\n",
        "                    # Estimation of task parameters\n",
        "                    pl, lxk, rik, fik, a[t], b[t], c[t] = bayesian_item_parameter_estimation(pl, lxk, rik, fik, resp[t], t, v, a[t], b[t], c[t])\n",
        "\n",
        "                    # Estimation of \"theta\" ability\n",
        "                    theta_eap, _ = expected_a_posteriori_mod(t, a[t], b[t], c[t], respostas_apresentadas[v], probs, num, tarefas_apresentadas[v])\n",
        "                    theta_100[v] = theta_eap\n",
        "\n",
        "\n",
        "                    # Solve the LP for each submission (item presented to a volunteer)\n",
        "                    df_s = linear_programming_mod(n_questions, v + 1, a, b, c, theta_100, n_tries_100, n_solutions, vezes_resolvidas, ep)\n",
        "                    t = pl_policy(v, df_s)  # Presents a task and depending on the answer, the theta estimate will be updated and the next question to be presented will be updated\n",
        "\n",
        "                else:\n",
        "                    t = -1\n",
        "\n",
        "                if t == -1:\n",
        "                    break\n",
        "                else:\n",
        "                    # Verification by enem data if the student solved the task\n",
        "                    # resp = np.array(df_resp.iloc[sampled_volunteers[v + n_volunteers * ep]])\n",
        "                    resolvida = resp[t]  # = u_li\n",
        "\n",
        "                    # Updates the number of times that task has been solved and increases attempts\n",
        "                    vezes_resolvidas[t] += resolvida\n",
        "                    tentativas[v] += 1\n",
        "                    tarefas_apresentadas[v].append(t)\n",
        "                    respostas_apresentadas[v].append(resp[t])\n",
        "\n",
        "            qtd_total_presented += tentativas[v]\n",
        "\n",
        "            df_new_resource['Episódio'] = [ep]*len(tarefas_apresentadas[v])\n",
        "            df_new_resource['Recurso']  = [v]*len(tarefas_apresentadas[v])\n",
        "            df_new_resource['Tarefas apresentadas'] = tarefas_apresentadas[v]\n",
        "            df_new_resource['Respostas apresentadas'] = respostas_apresentadas[v]\n",
        "\n",
        "            df_new_ep = df_new_ep.append(df_new_resource)\n",
        "\n",
        "\n",
        "            df_new_ep_tasks_param['Episódio'] = [ep]*n_questions\n",
        "            df_new_ep_tasks_param['Tarefa'] = list(range(n_questions))\n",
        "            df_new_ep_tasks_param['a'] = a\n",
        "            df_new_ep_tasks_param['b'] = b\n",
        "            df_new_ep_tasks_param['c'] = c\n",
        "\n",
        "\n",
        "        qtd_total_solucoes.append(vezes_resolvidas.sum())\n",
        "\n",
        "        # Calculate the time at the and of the episode\n",
        "        end = time.time()\n",
        "\n",
        "        # Save the number of solutions at the end of each episode\n",
        "        cells = worksheet.range('A' + str(ep+1) + ':G' + str(ep+1))\n",
        "        cells[0].value = ep\n",
        "        cells[1].value = vezes_resolvidas.sum()\n",
        "        cells[2].value = end - start\n",
        "        cells[3].value = qtd_total_presented\n",
        "        worksheet.update_cells(cells)\n",
        "\n",
        "        if ep == 0:\n",
        "            gd.set_with_dataframe(worksheet=worksheet_ass, dataframe=df_new_ep, include_index=False, include_column_header=False)\n",
        "\n",
        "            gd.set_with_dataframe(worksheet=worksheet_tasks_param, dataframe=df_new_ep_tasks_param, include_index=False, include_column_header=False)\n",
        "\n",
        "        else:\n",
        "            df_values = df_new_ep.values.tolist()\n",
        "            gs_ass.values_append('Página1', {'valueInputOption': 'RAW'}, {'values': df_values})\n",
        "\n",
        "            df_values_ = df_new_ep_tasks_param.values.tolist()\n",
        "            gs_tasks_param.values_append('Página1', {'valueInputOption': 'RAW'}, {'values': df_values_})\n",
        "\n",
        "\n",
        "    qtd_total_solucoes = np.array(qtd_total_solucoes)\n",
        "\n",
        "\n",
        "    # Printing the results\n",
        "    print('\\nProcess: {0}, Level: {1}'.format(process, level))\n",
        "    print(\"Mean of solutions for simulating {0} times: {1}\".format(n_episodes, np.mean(qtd_total_solucoes)))\n",
        "    print(\"Standard deviation of solutions for simulating {0} times: {1}\".format(n_episodes, np.std(qtd_total_solucoes)))\n",
        "    #print(\"Mean of tries for simulating {0} times: {1}\".format(n_episodes, qtd_total_presented / n_episodes))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNexBgJUIQ7rp8DYYj/7JHN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}